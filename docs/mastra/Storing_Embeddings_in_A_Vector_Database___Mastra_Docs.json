{
    "id": "https://mastra.ai/docs/rag/vector-databases",
    "title": "Storing Embeddings in A Vector Database | Mastra Docs",
    "url": "https://mastra.ai/docs/rag/vector-databases",
    "author": "",
    "text": "\n After generating embeddings, you need to store them in a database that supports vector similarity search. Mastra provides a consistent interface for storing and querying embeddings across different vector databases. \n Supported databases \n PostgreSQL with PgVector \n Best for teams already using PostgreSQL who want to minimize infrastructure complexity: \n Using Vector Storage \n Once initialized, all vector stores share the same interface for creating indexes, upserting embeddings, and querying. \n Creating Indexes \n Before storing embeddings, you need to create an index with the appropriate dimension size for your embedding model: \n The dimension size must match the output dimension of your chosen embedding model. Common dimension sizes are: \n \n OpenAI text-embedding-3-small: 1536 dimensions \n OpenAI text-embedding-3-large: 3072 dimensions \n Cohere embed-multilingual-v3: 1024 dimensions \n \n Upserting Embeddings \n After creating an index, you can store embeddings along with their basic metadata: \n The upsert operation: \n \n Takes an array of embedding vectors and their corresponding metadata \n Updates existing vectors if they share the same ID \n Creates new vectors if they don’t exist \n Automatically handles batching for large datasets \n \n Adding Metadata \n Vector stores support rich metadata for advanced filtering and organization. You can add any JSON-serializable fields that will help with retrieval. \n Reminder: Metadata is stored as a JSON field with no fixed schema, so you’ll want to name your fields consistently and apply a consistent schema, or your queries will return unexpected results. \n Key metadata considerations: \n \n Be strict with field naming - inconsistencies like ‘category’ vs ‘Category’ will affect queries \n Only include fields you plan to filter or sort by - extra fields add overhead \n Add timestamps (e.g., ‘createdAt’, ‘lastUpdated’) to track content freshness \n \n Best Practices \n \n Create indexes before bulk insertions \n Use batch operations for large insertions (the upsert method handles batching automatically) \n Only store metadata you’ll query against \n Match embedding dimensions to your model (e.g., 1536 for ) \n \n Examples \n For complete examples of different vector store implementations, see: \n \n Insert Embedding in PgVector \n Insert Embedding in Pinecone \n Insert Embedding in Qdrant \n Insert Embedding in Chroma \n Insert Embedding in Astra DB \n Insert Embedding in LibSQL \n Insert Embedding in Upstash \n Insert Embedding in Cloudflare Vectorize \n Basic RAG with Vector Storage \n Chunking and Embedding Retrieval",
    "image": "https://mastra.ai/api/og/docs?title=Storing%20Embeddings%20in%20A%20Vector%20Database%20%7C%20Mastra%20Docs",
    "extras": {
        "links": [
            "https://mastra.ai/",
            "https://mastra.ai/docs",
            "https://mastra.ai/examples",
            "https://mastra.ai/showcase"
        ]
    }
}