{
    "id": "https://mastra.ai/docs/agents/overview",
    "title": "Creating and Calling Agents | Agent Documentation | Mastra",
    "url": "https://mastra.ai/docs/agents/overview",
    "publishedDate": "1999-10-01T00:00:00.000Z",
    "author": "",
    "text": "\n Agents in Mastra are systems where the language model can autonomously decide on a sequence of actions to perform tasks. They have access to tools, workflows, and synced data, enabling them to perform complex tasks and interact with external systems. Agents can invoke your custom functions, utilize third-party APIs through integrations, and access knowledge bases you have built. \n Agents are like employees who can be used for ongoing projects. They have names, persistent memory, consistent model configurations, and instructions across calls, as well as a set of enabled tools. \n 1. Creating an Agent \n To create an agent in Mastra, you use the Agent class and define its properties: \n src/mastra/agents/index.ts import { Agent } from \" @mastra/core/agent \"; \n import { openai } from \" @ai-sdk/openai \"; \n \n export const myAgent = new Agent ({ \n name: \" My Agent \", \n instructions: \" You are a helpful assistant. \", \n model: openai ( \" gpt-4o-mini \"), \n}); \n Note: Ensure that you have set the necessary environment variables, such as your OpenAI API key, in your.env file: \n.env OPENAI_API_KEY=your_openai_api_key \n Also, make sure you have the @mastra/core package installed: \n Registering the Agent \n Register your agent with Mastra to enable logging and access to configured tools and integrations: \n import { Mastra } from \" @mastra/core \"; \n import { myAgent } from \"./agents \"; \n \n export const mastra = new Mastra ({ \n agents: { myAgent }, \n}); \n 2. Generating and streaming text \n Generating text \n Use the.generate() method to have your agent produce text responses: \n const response = await myAgent. generate ([ \n { role: \" user \", content: \" Hello, how can you assist me today? \" }, \n]); \n \n console. log ( \" Agent: \", response.text); \n For more details about the generate method and its options, see the generate reference documentation. \n Streaming responses \n For more real-time responses, you can stream the agent’s response: \n const stream = await myAgent. stream ([ \n { role: \" user \", content: \" Tell me a story. \" }, \n]); \n \n console. log ( \" Agent: \"); \n \n for await ( const chunk of stream.textStream) { \n process.stdout. write (chunk); \n} \n For more details about streaming responses, see the stream reference documentation. \n 3. Structured Output \n Agents can return structured data by providing a JSON Schema or using a Zod schema. \n Using JSON Schema \n const schema = { \n type: \" object \", \n properties: { \n summary: { type: \" string \" }, \n keywords: { type: \" array \", items: { type: \" string \" } }, \n }, \n additionalProperties: false, \n required: [ \" summary \", \" keywords \"], \n}; \n \n const response = await myAgent. generate ( \n [ \n { \n role: \" user \", \n content: \n \" Please provide a summary and keywords for the following text: ... \", \n }, \n ], \n { \n output: schema, \n }, \n); \n \n console. log ( \" Structured Output: \", response.object); \n Using Zod \n You can also use Zod schemas for type-safe structured outputs. \n First, install Zod: \n Then, define a Zod schema and use it with the agent: \n import { z } from \" zod \"; \n \n // Define the Zod schema \n const schema = z. object ({ \n summary: z. string (), \n keywords: z. array (z. string ()), \n}); \n \n // Use the schema with the agent \n const response = await myAgent. generate ( \n [ \n { \n role: \" user \", \n content: \n \" Please provide a summary and keywords for the following text: ... \", \n }, \n ], \n { \n output: schema, \n }, \n); \n \n console. log ( \" Structured Output: \", response.object); \n Using Tools \n If you need to generate structured output alongside tool calls, you’ll need to use the experimental_output property instead of output. Here’s how: \n const schema = z. object ({ \n summary: z. string (), \n keywords: z. array (z. string ()), \n}); \n \n const response = await myAgent. generate ( \n [ \n { \n role: \" user \", \n content: \n \" Please analyze this repository and provide a summary and keywords... \", \n }, \n ], \n { \n // Use experimental_output to enable both structured output and tool calls \n experimental_output: schema, \n }, \n); \n \n console. log ( \" Structured Output: \", response.object); \n This allows you to have strong typing and validation for the structured data returned by the agent. \n 4. Multi-step Tool use Agents \n Agents can be enhanced with tools - functions that extend their capabilities beyond text generation. Tools allow agents to perform calculations, access external systems, and process data. For details on creating and configuring tools, see the Adding Tools documentation. \n Using maxSteps \n The maxSteps parameter controls the maximum number of sequential LLM calls an agent can make, particularly important when using tool calls. By default, it is set to 1 to prevent infinite loops in case of misconfigured tools. You can increase this limit based on your use case: \n src/mastra/agents/index.ts import { Agent } from \" @mastra/core/agent \"; \n import { openai } from \" @ai-sdk/openai \"; \n import * as mathjs from \" mathjs \"; \n import { z } from \" zod \"; \n \n export const myAgent = new Agent ({ \n name: \" My Agent \", \n instructions: \" You are a helpful assistant that can solve math problems. \", \n model: openai ( \" gpt-4o-mini \"), \n tools: { \n calculate: { \n description: \" Calculator for mathematical expressions \", \n schema: z. object ({ expression: z. string () }), \n execute: async ({ expression }) =&gt; mathjs. evaluate (expression), \n }, \n }, \n}); \n \n const response = await myAgent. generate ( \n [ \n { \n role: \" user \", \n content: \n \" If a taxi driver earns $9461 per hour and works 12 hours a day, how much does they earn in one day? \", \n }, \n ], \n { \n maxSteps: 5, // Allow up to 5 tool usage steps \n }, \n); \n Using onStepFinish \n You can monitor the progress of multi-step operations using the onStepFinish callback. This is useful for debugging or providing progress updates to users.\n onStepFinish is only available when streaming or generating text without structured output. \n src/mastra/agents/index.ts const response = await myAgent. generate ( \n [{ role: \" user \", content: \" Calculate the taxi driver's daily earnings. \" }], \n { \n maxSteps: 5, \n onStepFinish: ({ text, toolCalls, toolResults }) =&gt; { \n console. log ( \" Step completed: \", { text, toolCalls, toolResults }); \n }, \n }, \n); \n Using onFinish \n The onFinish callback is available when streaming responses and provides detailed information about the completed interaction. It is called after the LLM has finished generating its response and all tool executions have completed.\nThis callback receives the final response text, execution steps, token usage statistics, and other metadata that can be useful for monitoring and logging: \n src/mastra/agents/index.ts const stream = await myAgent. stream ( \n [{ role: \" user \", content: \" Calculate the taxi driver's daily earnings. \" }], \n { \n maxSteps: 5, \n onFinish: ({ \n steps, \n text, \n finishReason, // 'complete', 'length', 'tool', etc. \n usage, // token usage statistics \n reasoningDetails, // additional context about the agent's decisions \n }) =&gt; { \n console. log ( \" Stream complete: \", { \n totalSteps: steps.length, \n finishReason, \n usage, \n }); \n }, \n }, \n); \n 5. Running Agents \n Mastra provides a CLI command mastra dev to run your agents behind an API. By default, this looks for exported agents in files in the src/mastra/agents directory. \n Starting the Server \n This will start the server and make your agent available at http://localhost:4111/api/agents/myAgent/generate. \n Interacting with the Agent \n You can interact with the agent using curl from the command line: \n curl -X POST http://localhost:4111/api/agents/myAgent/generate \\ \n -H \" Content-Type: application/json \" \\ \n -d ' { \n \"messages\": [ \n { \"role\": \"user\", \"content\": \"Hello, how can you assist me today?\" } \n ] \n } ' \n Next Steps \n \n Learn about Agent Memory in the Agent Memory guide. \n Learn about Agent Tools in the Agent Tools guide. \n See an example agent in the Chef Michel example. \n",
    "image": "https://mastra.ai/api/og/docs?title=Creating%20and%20Calling%20Agents%20|%20Agent%20Documentation%20|%20Mastra&description=Overview%20of%20agents%20in%20Mastra,%20detailing%20their%20capabilities%20and%20how%20they%20interact%20with%20tools,%20workflows,%20and%20external%20systems.",
    "favicon": "https://mastra.ai/favicon.ico",
    "extras": {
        "links": [
            "https://mastra.ai/docs/agents/overview",
            "https://mastra.ai/",
            "https://mastra.ai/docs",
            "https://mastra.ai/examples"
        ]
    }
}